import os
import torch
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
from PIL import Image
import cv2
import numpy as np
from diffusers.utils import load_image

# ------------------------------------------------
# 1. GPU ë° ëª¨ë¸ ë¡œë“œ
# ------------------------------------------------
print("GPU ë° ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤... â³")

# GPU ì‚¬ìš© ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"

# ControlNet ëª¨ë¸ ë¡œë“œ (Canny Edge Detection)
controlnet = ControlNetModel.from_pretrained(
    "lllyasviel/sd-controlnet-canny",
    torch_dtype=torch.float16,
    use_safetensors=True
).to(device)

# SD 1.5 ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ê³¼ ControlNetì„ í•¨ê»˜ ë¡œë“œ
# ì—¬ê¸°ì„œ StableDiffusionPipeline ëŒ€ì‹  StableDiffusionControlNetPipelineì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
pipeline = StableDiffusionControlNetPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    controlnet=controlnet,
    torch_dtype=torch.float16,
    use_safetensors=True
).to(device)

# í•™ìŠµëœ LoRA ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ì—¬ ìŠ¤íƒ€ì¼ì„ ì ìš©í•©ë‹ˆë‹¤.
lora_path = "sd15_lora_masterpiece"
pipeline.load_lora_weights(lora_path, weight_name="pytorch_lora_weights.safetensors")

# ------------------------------------------------
# 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ìŠ¤íƒ€ì¼ ë³€í™˜ (ControlNet + LoRA)
# ------------------------------------------------
print("\ní…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ìŠ¤íƒ€ì¼ì„ ì ìš©í•©ë‹ˆë‹¤. ğŸ–¼ï¸")

# í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
test_image_path = "portrait.jpg"
if not os.path.exists(test_image_path):
    print(f"âŒ ì˜¤ë¥˜: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ '{test_image_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    exit(1)

# ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
init_image = load_image(test_image_path).convert("RGB")
init_image = init_image.resize((512, 512))

# Canny ì—£ì§€ ë§µ ìƒì„± (ì›ë³¸ ì´ë¯¸ì§€ë¡œë¶€í„° ìœ¤ê³½ì„  ì¶”ì¶œ)
image_np = np.array(init_image)
image_canny = cv2.Canny(image_np, 100, 200)
image_canny = Image.fromarray(image_canny)

# í”„ë¡¬í”„íŠ¸ ì„¤ì • (LoRA í•™ìŠµ í”„ë¡¬í”„íŠ¸ì™€ ìœ ì‚¬í•˜ê²Œ)
prompt = "masterpiece oil painting, highly detailed, high quality"
negative_prompt = "unwanted,lowres, bad anatomy, bad hands, cropped, worst quality, deformed,undesired"

# ì´ë¯¸ì§€ ìƒì„±
# ControlNetì€ image ì¸ìˆ˜ì— Canny ì—£ì§€ ë§µì„ ë°›ì•„ì„œ ìœ¤ê³½ì„ ì„ ìœ ì§€í•©ë‹ˆë‹¤.
generator = torch.Generator(device).manual_seed(100)
generated_images = pipeline(
    prompt=prompt,
    negative_prompt=negative_prompt,
    image=image_canny, # <--- Canny ì—£ì§€ ë§µì„ ì‚¬ìš©í•˜ì—¬ êµ¬ë„ ì œì–´
    num_inference_steps=25,
    generator=generator
).images[0]

# ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
output_image_path = "result_portrait_controlnet_combined.png"
generated_images.save(output_image_path)
print(f"\nìŠ¤íƒ€ì¼ì´ ì ìš©ëœ ì´ë¯¸ì§€ê°€ '{output_image_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. âœ…")